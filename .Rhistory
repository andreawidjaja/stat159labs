*Source file*
```{r, results='asis', echo=FALSE}
includeSourceDocuments()
```
<!-- Don't edit the material above this line -->
#Bicycle-Use Patterns
```{r}
Stations <- mosaic::read.file("http://tiny.cc/dcf/DC-Stations.csv")
data_site <- "http://tiny.cc/dcf/2014-Q4-Trips-History-Data-Small.rds"
Trips <- readRDS(gzcon(url(data_site)))
```
##Time of day
###1
A density plot of the events versus sdate. Your plot should look like:
```{r}
Trips %>%
ggplot(aes(x = sdate)) +
geom_density()
```
###2
A density plot of the events versus time of day. You can use lubridate::hour(), and lubridate::minute() to extract the hour of the day and minute within the hour from sdate, e.g.
```{r}
Trips %>%
mutate(time_of_day = lubridate::hour(sdate) + lubridate::minute(sdate) / 60) %>%
ggplot(aes(x = time_of_day)) +
geom_density()
```
###3
Facet (2) by day of the week. (Use lubridate::wday() to generate day of the week.)
```{r}
Trips %>%
mutate(time_of_day = lubridate::hour(sdate) + lubridate::minute(sdate) / 60) %>%
mutate(day_of_week = lubridate::wday(sdate)) %>%
ggplot(aes(x = time_of_day)) +
geom_density() +
facet_wrap(~day_of_week)
```
###4
Set the fill aesthetic for geom_density() to the client variable. You may also want to set the alpha for transparency and color=NA to suppress the outline of the density function.
```{r}
Trips %>%
mutate(time_of_day = lubridate::hour(sdate) + lubridate::minute(sdate) / 60) %>%
mutate(day_of_week = lubridate::wday(sdate)) %>%
ggplot(aes(x = time_of_day)) +
geom_density(color = NA, alpha = 0.3, aes(fill = client)) +
facet_wrap(~day_of_week)
```
###5
Same as (4) but using geom_density() with the argument position = position_stack().
```{r}
Trips %>%
mutate(time_of_day = lubridate::hour(sdate) + lubridate::minute(sdate) / 60) %>%
mutate(day_of_week = lubridate::wday(sdate)) %>%
ggplot(aes(x = time_of_day)) +
geom_density(color = NA, alpha = 0.3, aes(fill = client), position = position_stack()) +
facet_wrap(~day_of_week)
```
* In your opinion, which of these graphics is most effective at telling an interesting story?
The one with posititon=position_stack is most effective.It eases the graph comparison.
###6
* Facet on wday
```{r}
Trips %>%
mutate(time_of_day = lubridate::hour(sdate) + lubridate::minute(sdate) / 60) %>%
mutate(wday = ifelse(lubridate::wday(sdate) %in% c(1,7), "weekend", "weekday")) %>%
ggplot(aes(x = time_of_day)) +
facet_wrap(~wday) +
geom_density(position = position_stack(), color = NA, alpha = 0.3, aes(fill = client))
```
* Facet on client
```{r}
Trips %>%
mutate(time_of_day = lubridate::hour(sdate) + lubridate::minute(sdate) / 60) %>%
mutate(wday = ifelse(lubridate::wday(sdate) %in% c(1,7), "weekend", "weekday")) %>%
ggplot(aes(x = time_of_day)) +
facet_wrap(~client) +
geom_density(position = position_stack(), color = NA, alpha = 0.3, aes(fill = wday))
```
It is better to facet on wday and fill with client because this way, it is easier to tell on whether on weekends or weekdays is there more clients.
##Trip distance
###1
Make two copies of Stations, which we’ll call Left and Right. Left will have names sstation, lat, and long. Right will have names estation, lat2, and long2. The other variables, nbBikes and nbEmptyDocks should be dropped. Use the function dpylr::rename() to do the renaming of name,lat, and long (i.e. dyplyr::rename(sstation=name)).
```{r}
Stations <- mosaic::read.file("http://tiny.cc/dcf/DC-Stations.csv")
left <- Stations %>%
select(name, lat, long) %>%
rename(sstation=name)
right <- Stations %>%
select(name, lat, long) %>%
rename(estation=name) %>%
rename(lat2=lat) %>%
rename(long2=long)
head(left)
head(right)
```
###2
Join Left and Right with a full outer join. This is a join in which every case in Left is matched to every case in Right. You can accomplish the full outer join with left%>% merge(right,all=TRUE).
```{r}
jointdata <- left%>% merge(right,all=TRUE)
head(jointdata)
```
```{r}
source("http://tiny.cc/dcf/haversine.R")
```
###3.
Using the merged table, add a variable dist like this:
The end result, which we’ll call Distances, should look like this:
```{r}
finaldata <- jointdata %>% mutate(dist = haversine(lat, long, lat2, long2))
head(finaldata)
```
```{r}
Distances <- joinData %>%
mutate(dist = haversine(lat, long, lat2, long2)) %>%
select(sstation, estation, dist)
head(Distances)
Trips = inner_join(Trips, Distances)
```
Distances <- joinData %>%
mutate(dist = haversine(lat, long, lat2, long2)) %>%
select(sstation, estation, dist)
head(Distances)
Trips = inner_join(Trips, Distances)
Distances <- jointdata %>%
mutate(dist = haversine(lat, long, lat2, long2)) %>%
select(sstation, estation, dist)
head(Distances)
final<-inner_join(Trips, Distances)
head(final)
file.choose()
x <- seq(from = 0, to = 8, by = 2)
x[x < 4] <- NA
x[] <- 0
x <- 0
x
x[]
x <- seq(from = 0, to = 8, by = 2)
x
x[x < 4] <- NA
x
x[]<- 0
x
x <- 0
0
file.choose()
library(DataComputing)
BabyNames %>%
group_by(name) %>%  #this groups the same name
summarise(tot = sum(count))
BabyNames %>%
group_by(name) %>%  #this groups the same name
summarise(tot = sum(count)) %>% #creates data set which consists of the variabe name and a new variable called tot which summarises the total number of babies with that name. a col that shows how many times each name appear in data set
mutate(rank = rank(desc(tot)))
max(rank)
BabyNames %>%
group_by(name) %>%  #this groups the same name
summarise(tot = sum(count)) %>% #creates data set which consists of the variabe name and a new variable called tot which summarises the total number of babies with that name. a col that shows how many times each name appear in data set
mutate(rank = rank(desc(tot))) %>%
max(rank)
BabyNames %>%
+     group_by(name) %>%  #this groups the same name
+     summarise(tot = sum(count)) %>%
arrange(desc(total))
BabyNames %>%
group_by(name) %>%
summarise(tot=sum(count))
BabyNames %>%
+ group_by(name) %>%
+ summarise(tot=sum(count))
BabyNames %>%
group_by(name) %>%
summarise(tot=sum(count))
BabyNames %>%
group_by(name) %>%
summarise(tot=sum(count)) %>%
mutate(rank = arrange(desc(tot)))
BabyNames %>%
group_by(name) %>%
summarise(tot=sum(count)) %>%
mutate(rank=arrange(tot))
BabyNames %>%
+ group_by(name) %>%
+ summarise(tot=sum(count)) %>%
+ mutate(rank=arrange(tot))
BabyNames %>%
group_by(name) %>%
summarise(tot=sum(count)) %>%
arrange(tot)
BabyNames %>%+ group_by(name) %>%
+ summarise(tot=sum(count)) %>%
+ arrange(tot)
BabyNames %>%
group_by(name) %>%
summaraise(tot=sum(count)) %>%
arrange(desc(tot))
BabyNames %>%
+ group_by(name) %>%
+ summarise(tot=sum(count)) %>%
+ arrange(desc(tot))
BabyNames %>%
group_by(name) %>%
summarise(tot=sum(count)) %>%
arrange(desc(tot))
BabyNames %>%+ group_by(name) %>%
+ summarise(tot=sum(count)) %>%
+ arrange(desc(tot))
BabyNames %>%
group_by(name) %>%
summarise(tot=sum(count)) %>%
mutate(rank=rank(desc(tot))) %>%
arrange(desc(tot))
BabyNames %>%+ group_by(name) %>%
+ summarise(tot=sum(count)) %>%
+ mutate(rank=rank(desc(tot))) %>%
+ arrange(desc(tot))
BabyNames %>%
group_by(name) %>%
summarise(tot=sum(count)) %>%
mutate(rank=rank(desc(tot))) %>%
arrange(desc(rank))
View(BabyNames)
BabyNames %>%
filter(name==Marie)
BabyNames %>%
filter(name=="Marie")
BabyNames %>%
group_by(name) %>%
tally(rank=sort(TRUE))
BabyNames %>%
group_by(name) %>%
tally(sort=TRUE)
View(InputData)
ggplot(mosaicData::TenMileRace, aes(x = net)) +
geom_density(alpha=0.5, color=NA, aes(fill = sex)) +
xlab("Running time (s)") +
scale_fill_grey() +
theme(panel.background = element_rect(fill='white', colour='black'))
ggplot(mosaicData::TenMileRace, aes(x = net)) +
geom_density(alpha=0.5, color=NA, aes(fill = sex)) +
xlab("Running time (s)") +
scale_fill_grey() +
theme(panel.background = element_rect(fill='white', colour='black'))
s
scale_fill_grey()
BodyTypes
library(DataComputing)
Minneapolis2013
Mineeapolis2013 %>%
group_by(First) %>%
summarise(totalvotes=n())
library(magrittr)
Minneapolis2013 %>%
group_by(First) %>%
summarise(totalvotes=n())
data <- read.csv("/Users/Adam/Desktop/stat133lectures_hw_lab/exam/practice/dat.csv")
file.choose
file.choose()
file.choose()
file.choose()
load("/Users/Andrea/Desktop/UCB/lab10.rda")
a <- load("/Users/Andrea/Desktop/UCB/lab10.rda")
a
View(a)
load("/Users/Andrea/Desktop/lab10.rda")
load("/Users/Andrea/Desktop/lab10.rda")
myData
file.choose()
quakes
head(quakes)
quakes <- read.file("/Users/Andrea/Downloads/NCEDC3+quakes.csv")
head(quakes)
vec_long <- quakes %>%
select(long)
head(vec_long)
vec_lat <- quakes %>%
select(lat)
head(vec_lat)
library("DataComputing", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("magrittr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
quakes <- read.file("/Users/Andrea/Downloads/NCEDC3+quakes.csv")
head(quakes)
vec_long <- quakes %>%
select(long)
head(vec_long)
vec_lat <- quakes %>%
select(lat)
head(vec_lat)
```{r}
quakes <- read.file("/Users/Andrea/Downloads/NCEDC3+quakes.csv")
head(quakes)
vec_long <- quakes %>%
select("long")
head(vec_long)
vec_lat <- quakes %>%
select("lat")
head(vec_lat)
```
head(quakes)
quakes <- read.file("/Users/Andrea/Downloads/NCEDC3+quakes.csv")
head(quakes)
dataquake <- quakes %>%
filter(Magnitude > 4)
head(dataquake)
raw <- read.file("/Users/Andrea/Downloads/NCEDC3+quakes.csv")
head(raw)
quakes <- raw %>%
filter(Magnitude > 4)
head(quakes)
vec_long <- quakes[3]
head(vec_long)
vec_long <- quakes[3]
head(vec_long)
vec_lat <- quakes[4]
head(vec_lat)
head(quakes)
raw <- read.file("/Users/Andrea/Downloads/NCEDC3+quakes.csv")
head(raw)
quakes <- raw %>%
filter(Magnitude > 4)
head(quakes)
vec_lat <- quakes[2]
head(vec_lat)
vec_long <- quakes[3]
head(vec_long)
library("XML", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
doc = newXMLDoc()
head(quakes)
library("DataComputing", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("magrittr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("plyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
file.choose()
microeconomic <- read.file("/Users/Andrea/Desktop/umkm.csv")
View(microeconomic)
install.packages("reshape")
library("reshape", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
number %>%
filter(Indicator == "Jumlah UMKM") %>%
ggplot(aes(x=Year, y=Value)) +
geom_point()
microeconomic <- read.file("/Users/Andrea/Desktop/umkm.csv")
number <- rename(microeconomic, c("indikator" = "Indicator", "satuan" = "Units", "tahun" = "Year", "nilai" = "Value"))
number %>%
filter(Indicator == "Jumlah UMKM") %>%
ggplot(aes(x=Year, y=Value)) +
geom_point()
dev.off()
file.choose
file.choose()
```{r, echo=FALSE}
gamma <- read.file("/Users/Andrea/Downloads/Excel CSV/Chapter 8/gamma-arrivals.csv")
```
file.choose()
install.packages("MASS")
library("MASS", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
?fitdistr
library(fitdistr)
?CRAN.packages
?dgamma
install.packages("testthat")
x <- {1,2,3,4}
x
x <- c(1,2,3,4)
range(x)
IQR(x)
sd(x)
median(x)
mean(x)
sum(is.na(x))
history
load('../data/regression.Rdata')
x <- load('../data/regression.Rdata')
x <- load('../data/regression.RData')
load("~/Desktop/UCB/Fall2016/STAT159/Homework/stat159-fall2016-hw03/data/correlation-matrix.RData")
load("~/Desktop/UCB/Fall2016/STAT159/Homework/stat159-fall2016-hw03/data/regression.RData")
x <- load("~/Desktop/UCB/Fall2016/STAT159/Homework/stat159-fall2016-hw03/data/correlation-matrix.RData")
names(x)
View*(x0)
View(x)
y <- load("~/Desktop/UCB/Fall2016/STAT159/Homework/stat159-fall2016-hw03/data/regression.RData")
View(y)
```{r results='asis', message=FALSE, echo=FALSE, warning=FALSE}
load('../data/correlation_matrix.Rdata')
library(xtable)
regression_table <- xtable(RegressionSummary$coefficients, digits=4,
caption='Information about Regression Coefficients - note that: Sales variable is measured in thousands of dollars, and the Media variables are in thousands of units')
print(regression_table, type = "latex", comment=FALSE, caption.placement='top')
```
---
title: "SimpVle Regression Analysis"
author: "Andrea Widjaja"
date: "10/14/16"
output: pdf_document
---
# Stat 159 Homework 2
# Abstract
This paper consists of the reproduced results from _Section 3.1 Simple Linear Regression_ from the book **An Introduction to Statistical Learning** _by Gareth James, Daniel Witten, Trevor Hastie, and Robert Tibshirani._ This paper will discuss topics of simple linear regression such as estimating the coefficients, assessing the accuracy of the coefficient estimates, and assessing the accuracy of the model using the least square approach.
# Introduction
# Data
The data set we are given is *Advertising.csv*, downloaded from `http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv.` This data set contains the sales(in thousands of units) of a product across 200 different markets and the amount spent(in thousands of dollars) in advertising for the product in each market. The advertising data contains budgets for three different medias: TV, radio and newspaper. It has 200 records and 5 variables(index, TV, Radio, Newspaper, Sales). Each record contains the information of advertising budget for TV, Radio, and Newspaper, including the sales progress for each market.
# Methodology
##Linear Regression
Suppose that we want to estimate a relationship between two variables $X$ and $Y$. We assume that there is a linear relationship between the Variable $X$ and Variable $Y$. For example, if we presume that a change in $X$ has an effect on $Y$, then we can say that $X$ is the independent variable, whereas $Y$ is the dependent variable. This relationship can be represented as a simple lienar model.
Regress $Y$ on $X$:
$$ Y = \beta_0 + \beta_1X $$
This, however, do not take into account for the error term/residual. The dependent variable $Y$, may not be perfectly predicted by the variable $X$. The error term/residual represents the difference between the results obtained by the model and real-world applications.
If we take into account for error, the linear regression will be:
$$ Y = \beta_0 + \beta_1X + \epsilon $$
For our case, we need to analyze the relationship between TV advertising and Sales. The first step we need to do is come up with a similar linear model. $X$, for example, can represent TV, whereas, $Y$ can represent Sales.
Regress Sales on TV advertising, taking into account for residual:
$$ Sales = \beta_0 + \beta_1 * TV + \epsilon $$
# Results
This scatterplot shows the least squares fit for the regression of Sales onto TV. The line represents a simple model that can be used to predict *Sales* using the TV medium.
```{r echo=FALSE, fig.width=6, fig.height=4, fig.pos='H', fig.align='center', fig.cap="Scatterplot with Fitted Regression Line - From the Advertising data, this shows the least squares fit for the regression of Sales onto TV. This means that, the purple line represents a simple model that can be used to predict sales using TV."}
library(png)
library(grid)
img <- readPNG("../images/scatterplot-tv-sales.png")
grid.raster(img)
```
```{r results='asis', message=FALSE, echo=FALSE, warning=FALSE}
load('../data/correlation_matrix.Rdata')
library(xtable)
regression_table <- xtable(RegressionSummary$coefficients, digits=4,
caption='Information about Regression Coefficients - note that: Sales variable is measured in thousands of dollars, and the Media variables are in thousands of units')
print(regression_table, type = "latex", comment=FALSE, caption.placement='top')
```
load("../data/regression.Rdata")
library(pander)
panderOptions("digits", 4)
pander(fit, caption = "Summary of Linear Regression Model of TV on Sales")
```{r results='asis', message=FALSE, echo=FALSE, warning=FALSE}
load('../data/regression.RData')
library(xtable)
regression_table2 <- xtable(regression_summary$coefficients, digits=4,
caption='Summary of Linear regression model')
print(regression_table2, type = "latex", comment=FALSE, caption.placement='top')
```
names(correlation_matrix)
ls(correlation_matrix)
str(correlation_matrix)
load("~/Desktop/UCB/Fall2016/STAT159/Homework/stat159-fall2016-hw03/data/correlation-matrix.RData")
isfar <- get(load("~/Desktop/UCB/Fall2016/STAT159/Homework/stat159-fall2016-hw03/data/correlation-matrix.RData"))
isfar
load("~/Desktop/UCB/Fall2016/STAT159/Homework/stat159-fall2016-hw03/data/regression.RData")
isfar2 <- get(load("~/Desktop/UCB/Fall2016/STAT159/Homework/stat159-fall2016-hw03/data/regression.RData"))
isfar2
isfar2$coefficients
names(isfar2)
TV_regression
Radio_regression
names(TV_regression)
xtable(TV_regression$coefficients)
str(TV_regression)
install.packages("pander")
library(pander)
lm(Sales~TV+Radio+Newspaper, data=advertising)
advertising <- read.csv('../../data/Advertising.csv')
read.csv(http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv)
curl -o http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv
http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv
curl -O "http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv"
advertising <- read.csv('../../data/Advertising.csv')
file.choose()
a <- read.file("/Users/Andrea/Desktop/UCB/Fall2016/STAT159/Homework/stat159-fall2016-hw02/data/Advertising.csv")
read.csv("/Users/Andrea/Desktop/UCB/Fall2016/STAT159/Homework/stat159-fall2016-hw02/data/Advertising.csv")
a <- read.csv("/Users/Andrea/Desktop/UCB/Fall2016/STAT159/Homework/stat159-fall2016-hw02/data/Advertising.csv")
object <- lm(Sales~TV+Radio+Newspaper, data=a)
object
summary(oobject)
summary(object)
summary(a)
cor (a)
a
head(a)
a['X'] <- NULL
head(a)
cor(a)
TV_regression
summary(TV_regression)
names(TV_regression)
TV_regression$residuals
$$ Cor(Y,\hat{y})^2 $$
$$ R^2 = \frac{(TSS - RSS)}{TSS} \ = 1 - \frac{RSS}{TSS} $$
install.packages("Shiny")
install.packages("shiny")
shiny::runApp('Desktop/UCB/Fall2016/STAT159/labs/lab3')
shiny::runApp('Desktop/UCB/Fall2016/STAT159/labs/lab3')
getwd
getwd()
file.choose()
setwd("/Users/Andrea/Desktop/UCB/Fall2016/STAT159/labs/lab3/app.R")
"/Users/Andrea/Desktop/UCB/Fall2016/STAT159/labs/lab3/app.R"
setwd(C://"/Users/Andrea/Desktop/UCB/Fall2016/STAT159/labs/lab3/app.R")
setwd(C://Andrea/Desktop/UCB/Fall2016/STAT159/labs/lab3/app.R)
setwd(C:/Users/Andrea/Desktop/UCB/Fall2016/STAT159/labs/lab3/app.R)
setwd("C:/Users/Andrea/Desktop/UCB/Fall2016/STAT159/labs/lab3/app.R")
cd
setwd("C:/Users/Andrea/Desktop/UCB/Fall2016/STAT159/labs/lab3")
shiny::runApp('Desktop/UCB/Fall2016/STAT159/labs/lab3')
adv_data <- read.csv("Advertising.csv")
ls
read.csv("Advertising.csv")
file.choose()
read.csv("/Users/Andrea/Desktop/UCB/Fall2016/STAT159/labs/lab3/Advertising.csv")
a <- read.csv("/Users/Andrea/Desktop/UCB/Fall2016/STAT159/labs/lab3/Advertising.csv")
head(a)
View(a)
shiny::runApp('Desktop/UCB/Fall2016/STAT159/labs/lab3')
shiny::runApp('Desktop/UCB/Fall2016/STAT159/labs/lab3')
shiny::runApp('Desktop/UCB/Fall2016/STAT159/labs/lab3')
shiny::runApp('Desktop/UCB/Fall2016/STAT159/labs/lab3')
shiny::runApp('Desktop/UCB/Fall2016/STAT159/labs/lab3')
shiny::runApp('Desktop/UCB/Fall2016/STAT159/labs/lab3')
